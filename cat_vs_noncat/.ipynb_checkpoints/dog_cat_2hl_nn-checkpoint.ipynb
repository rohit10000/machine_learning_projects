{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Cat classification with 2 hidden layers neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Importing python libraries</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Preprocessing step:</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('C:/Users/Rohit/Music/machine_learning_projects/cat_vs_noncat/images_dog_vs_cat_25000.npy')\n",
    "labels = np.load('C:/Users/Rohit/Music/machine_learning_projects/cat_vs_noncat/labels_dog_vs_cat_25000.npy')\n",
    "labels = np.array(labels).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 25000)\n",
      "(25000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 15000)\n"
     ]
    }
   ],
   "source": [
    "X = train_data[:,:15000]\n",
    "Y = labels[:15000,:]\n",
    "X_test = train_data[:, 15000:]\n",
    "Y_test = labels[15000:, :]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Hidden layers with units </i></b>\n",
    "\n",
    "<img src = \"./images/fig3.png\" style=\"height:300px;width:400;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = train_data.shape[0]\n",
    "n_h1 = 5\n",
    "n_h2 = 5\n",
    "n_y = 1\n",
    "layer_dims = (n_x, n_h1, n_h2, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs =[]\n",
    "m = X.shape[1]\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1/(1 + np.exp(-z.astype(float)))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "\tz = np.maximum(z, 0)\n",
    "\treturn z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Initialization of parameters. </i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameter(layer_dims):\n",
    "\tn_x, n_h1, n_h2, n_y = layer_dims\n",
    "\tW1 = np.random.randn(n_h1, n_x)*0.01\n",
    "\tb1 = np.zeros((n_h1, 1))\n",
    "\tW2 = np.random.randn(n_h2, n_h1)*0.01\n",
    "\tb2 = np.zeros((n_h2, 1)) \n",
    "\tW3 = np.random.randn(n_y, n_h2)*0.01\n",
    "\tb3 = np.zeros((n_y, 1))\n",
    "\n",
    "\tparameter = {\"W1\": W1,\n",
    "\t\t\"b1\": b1,\n",
    "\t\t\"W2\": W2,\n",
    "\t\t\"b2\": b2,\n",
    "\t\t\"W3\": W3,\n",
    "\t\t\"b3\": b3}\n",
    "\n",
    "\treturn parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "\tcost = - np.sum(Y * np.log(AL) + (1 - Y) * np.log(1 - AL))/m\n",
    "\treturn cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameter(parameters, grads, learning_rate):\n",
    "\n",
    "\tL = len(parameters) // 2 # number of layers in the neural network\n",
    "\tfor l in range(L):\n",
    "\t\tparameters[\"W\" + str(l+1)] = parameters[\"W\"+str(l+1)] - learning_rate*grads[\"dW\"+str(l+1)]\n",
    "\t\tparameters[\"b\" + str(l+1)] = parameters[\"b\"+str(l+1)] - learning_rate*grads[\"db\"+str(l+1)]\n",
    "\t\treturn parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Y, parameters):\n",
    "\tW1, b1, W2, b2, W3, b3 = parameters\n",
    "\tA1 = relu(np.dot(W1, X) + b1)\n",
    "\tA2 = relu(np.dot(W2, A1) + b2)\n",
    "\tA3 = sigmoid(np.dot(W3, A2) + b3)\n",
    "\tA3[A3 < 0.5] = 0\n",
    "\tA3[A3 >= 0.5] = 1\n",
    "\treturn A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(A_prev, W, b, activation):\n",
    "\tZ = np.dot(W, A_prev) + b\n",
    "\tif activation == \"sigmoid\":\n",
    "\t\tA = sigmoid(Z)\n",
    "\tif activation == \"relu\":\n",
    "\t\tA = relu(Z)\n",
    "\tif activation == \"tanhx\":\n",
    "\t\tA = np.tanh(Z)\n",
    "\n",
    "\tcache = (A_prev, W, b, A, Z)\n",
    "\treturn A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Gradient calculation using Forward and Backward Propagation</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(dA, Y, cache, activation):\n",
    "\tA_prev, W, b, A, Z = cache\n",
    "\tdZ=0\n",
    "\tif activation == \"sigmoid\":\n",
    "\t\tdZ = np.multiply(dA, A*(1-A))\n",
    "\tif activation == \"relu\":\n",
    "\t\tZ[Z > 0] = 1\n",
    "\t\tZ[Z < 0] = 0\n",
    "\t\tdZ = dA*Z\n",
    "\n",
    "\tif activation == \"tanhx\":\n",
    "\t\tdZ = dA*(1 - (np.tanh(Z))**2)\n",
    "\n",
    "\tdW = np.dot(dZ, A_prev.T)/m\n",
    "\tdb = np.sum(dZ, axis = 1, keepdims = True)/m\n",
    "\tdA_prev = np.dot(W.T, dZ)\n",
    "\treturn dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Optimization function</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X, Y, layer_dims, learning_rate, iterations):\n",
    "\n",
    "\tinitial_parameter = initialize_parameter(layer_dims)\n",
    "\tW1 = initial_parameter[\"W1\"]\n",
    "\tb1 = initial_parameter[\"b1\"]\n",
    "\tW2 = initial_parameter[\"W2\"]\n",
    "\tb2 = initial_parameter[\"b2\"]\n",
    "\tW3 = initial_parameter[\"W3\"]\n",
    "\tb3 = initial_parameter[\"b3\"]\n",
    "\tupdated_parameter = initial_parameter\n",
    "\tfor i in range(iterations):\n",
    "\t\tA1, cache1 = forward_propagation(X, W1, b1, \"relu\")\n",
    "\t\tA2, cache2 = forward_propagation(A1, W2, b2, \"relu\")\n",
    "\t\tA3, cache3 = forward_propagation(A2, W3, b3, \"sigmoid\")\n",
    "        \n",
    "\t\tcost = compute_cost(A3, Y)\n",
    "\t\tdA3 = -Y.T/A3 +(1-Y.T)/(1-A3)\n",
    "\t#\tprint(dA2)\n",
    "\t\tdA2, dW3, db3 = backward_propagation(dA3, Y, cache3, \"sigmoid\")\n",
    "\t\tdA1, dW2, db2 = backward_propagation(dA2, Y, cache2, \"relu\")\n",
    "\t\tdA0, dW1, db1 = backward_propagation(dA1, Y, cache1, \"relu\")\n",
    "\t\tgrads = {\"dW1\": dW1,\n",
    "\t\t\t\t\"db1\": db1,\n",
    "\t\t\t\t\"dW2\": dW2,\n",
    "\t\t\t\t\"db2\": db2,\n",
    "\t\t\t\t\"dW3\": dW3,\n",
    "\t\t\t\t\"db3\": db3}\n",
    "\n",
    "\t\t#print(\"This is gradient{}-{}\".format(grads[\"dW1\"], W2))\n",
    "\n",
    "\t\tupdated_parameter = update_parameter(updated_parameter, grads, learning_rate)\n",
    "\t\tW1 = updated_parameter[\"W1\"]\n",
    "\t\tb1 = updated_parameter[\"b1\"]\n",
    "\t\tW2 = updated_parameter[\"W2\"]\n",
    "\t\tb2 = updated_parameter[\"b2\"]\n",
    "\t\tW3 = updated_parameter[\"W3\"]\n",
    "\t\tb3 = updated_parameter[\"b3\"]\n",
    "        \n",
    "\t\tif i % 10 == 0:\n",
    "\t\t\tprint(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "\t\tif i % 10 == 0:\n",
    "\t\t\tcosts.append(cost)\n",
    "\n",
    "\tfinal_parameters = (W1, b1, W2, b2, W3, b3)\n",
    "\treturn final_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 10397.207830883937\n",
      "Cost after iteration 10: 10397.207830856772\n",
      "Cost after iteration 20: 10397.207830829731\n",
      "Cost after iteration 30: 10397.207830802732\n",
      "Cost after iteration 40: 10397.207830775704\n",
      "Cost after iteration 50: 10397.207830748403\n",
      "Cost after iteration 60: 10397.207830721101\n",
      "Cost after iteration 70: 10397.207830694071\n",
      "Cost after iteration 80: 10397.207830666699\n",
      "Cost after iteration 90: 10397.207830639141\n"
     ]
    }
   ],
   "source": [
    "final_parameters = nn_model(X, Y, layer_dims, 0.0075, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Prediction on test data</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test  = predict(X_test, Y_test, final_parameters).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.4857\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: \", accuracy_score(Y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train  = predict(X, Y, final_parameters).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.4832\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \", accuracy_score(Y, pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style = \"color:red\">Note: </h3><b><i>This neural network model uses 3 layers i.e. 2 hidden layes and 1 output layer to predict 0/1. This model is trained on just 15000 train images and tested on 10000 test images.</i><b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
